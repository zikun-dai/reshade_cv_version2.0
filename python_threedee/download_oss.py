#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµç¨‹ï¼ˆå…¨è‡ªåŠ¨ç‰ˆæœ¬ï¼‰ï¼š
ä¸‹è½½ â†’ è§£å‹ â†’ éªŒè¯ â†’ å¤„ç† â†’ ä¸Šä¼  â†’ æ¸…ç†
å¼‚å¸¸æ•°æ®è‡ªåŠ¨è·³è¿‡ï¼Œè®°å½•æ—¥å¿—
"""
import os
import sys
import cv2
import glob
import shutil
import zipfile
import subprocess
import requests
import argparse
import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
from math import ceil
from PIL import Image
from urllib.parse import urlparse, unquote
from datetime import datetime
from collections import defaultdict

# ==================== é…ç½®å‚æ•° ====================
BASE_DIR = r"C:\Users\10762\Desktop\data\tmp"
OSS_BASE_PATH = "oss://antsys-robbyh20-b1/cyh/game_data_check/"
OSSUTIL_PATH = "ossutil"
GROUP_SIZE = 100

# éªŒè¯å‚æ•°ï¼ˆé›¶å®¹å¿æ¨¡å¼ï¼‰
VALIDATION_SAMPLE_RATE = 10  # é‡‡æ ·ç‡ï¼šæ¯Nå¸§æ£€æŸ¥ä¸€æ¬¡ï¼ˆæé«˜é€Ÿåº¦ï¼‰
DEPTH_ABNORMAL_MEAN_RANGE = (16400, 16600)  # å¼‚å¸¸depthå‡å€¼èŒƒå›´
DEPTH_ABNORMAL_STD_THRESHOLD = 10  # å¼‚å¸¸depthæ ‡å‡†å·®é˜ˆå€¼
# æ³¨æ„ï¼šä¸å†ä½¿ç”¨ACCEPTABLE_ERROR_RATEï¼Œå‘ç°ä»»ä½•å¼‚å¸¸ç«‹å³è·³è¿‡action


# æ—¥å¿—æ–‡ä»¶
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# ==================== æ—¥å¿—æ¨¡å— ====================
class ProcessLogger:
    """å¤„ç†æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_dir):
        self.log_dir = log_dir
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = os.path.join(log_dir, f"process_{timestamp}.log")
        self.error_file = os.path.join(log_dir, f"errors_{timestamp}.log")
        self.skipped_file = os.path.join(log_dir, f"skipped_{timestamp}.log")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_urls': 0,
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'actions_total': 0,
            'actions_skipped': 0,
            'actions_processed': 0
        }
    
    def log(self, message, level="INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_msg = f"[{timestamp}] [{level}] {message}"
        print(log_msg)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_msg + "\n")
    
    def log_error(self, url_idx, url, error_msg):
        """è®°å½•é”™è¯¯"""
        self.log(f"URL [{url_idx}] å¤±è´¥: {error_msg}", "ERROR")
        
        with open(self.error_file, 'a', encoding='utf-8') as f:
            f.write(f"[{url_idx}] {url}\n")
            f.write(f"é”™è¯¯: {error_msg}\n")
            f.write("-" * 60 + "\n")
    
    def log_skipped_action(self, action_name, reason, details):
        """è®°å½•è·³è¿‡çš„action"""
        self.log(f"è·³è¿‡ {action_name}: {reason}", "SKIP")
        
        with open(self.skipped_file, 'a', encoding='utf-8') as f:
            f.write(f"Action: {action_name}\n")
            f.write(f"åŸå› : {reason}\n")
            f.write(f"è¯¦æƒ…: {details}\n")
            f.write("-" * 60 + "\n")
    
    def summary(self):
        """è¾“å‡ºç»Ÿè®¡æ‘˜è¦"""
        self.log("\n" + "=" * 60, "SUMMARY")
        self.log("å¤„ç†ç»Ÿè®¡æ‘˜è¦", "SUMMARY")
        self.log("=" * 60, "SUMMARY")
        self.log(f"æ€»URLæ•°: {self.stats['total_urls']}", "SUMMARY")
        self.log(f"  æˆåŠŸ: {self.stats['success']}", "SUMMARY")
        self.log(f"  å¤±è´¥: {self.stats['failed']}", "SUMMARY")
        self.log(f"  è·³è¿‡: {self.stats['skipped']}", "SUMMARY")
        self.log(f"æ€»Actionsæ•°: {self.stats['actions_total']}", "SUMMARY")
        self.log(f"  å·²å¤„ç†: {self.stats['actions_processed']}", "SUMMARY")
        self.log(f"  å·²è·³è¿‡: {self.stats['actions_skipped']}", "SUMMARY")
        self.log("=" * 60, "SUMMARY")

# å…¨å±€æ—¥å¿—å¯¹è±¡
logger = None

def find_camera_or_meta_file(action_dir, frame_idx):
    """
    æŸ¥æ‰¾cameraæˆ–metaæ–‡ä»¶ï¼ˆå…¼å®¹ä¸¤ç§å‘½åï¼‰
    ä¼˜å…ˆçº§ï¼šcamera.json > meta.json
    è¿”å›ï¼šæ–‡ä»¶è·¯å¾„æˆ–None
    """
    frame_prefix = f"frame_{frame_idx:06d}"
    
    # ä¼˜å…ˆæŸ¥æ‰¾camera.json
    camera_path = os.path.join(action_dir, f"{frame_prefix}_camera.json")
    if os.path.exists(camera_path):
        return camera_path
    
    # å¦‚æœæ²¡æœ‰camera.jsonï¼ŒæŸ¥æ‰¾meta.json
    meta_path = os.path.join(action_dir, f"{frame_prefix}_meta.json")
    if os.path.exists(meta_path):
        return meta_path
    
    return None

def get_camera_meta_pattern():
    """è¿”å›camera/metaæ–‡ä»¶çš„globæ¨¡å¼"""
    return ["frame_*_camera.json", "frame_*_meta.json"]

# ==================== æ•°æ®éªŒè¯æ¨¡å— ====================
def check_depth_file(depth_path):
    """æ£€æŸ¥å•ä¸ªdepthæ–‡ä»¶æ˜¯å¦æ­£å¸¸"""
    try:
        depth_data = np.load(depth_path)
        
        mean_val = np.mean(depth_data)
        std_val = np.std(depth_data)
        min_val = np.min(depth_data)
        max_val = np.max(depth_data)
        
        # åˆ¤æ–­æ˜¯å¦å¼‚å¸¸ï¼šå‡å€¼åœ¨16499é™„è¿‘ä¸”æ ‡å‡†å·®å¾ˆå°
        is_abnormal = (DEPTH_ABNORMAL_MEAN_RANGE[0] < mean_val < DEPTH_ABNORMAL_MEAN_RANGE[1] 
                      and std_val < DEPTH_ABNORMAL_STD_THRESHOLD)
        
        return {
            'valid': not is_abnormal,
            'mean': mean_val,
            'std': std_val,
            'min': min_val,
            'max': max_val
        }
    except Exception as e:
        return {
            'valid': False,
            'error': str(e)
        }

def check_camera_file(camera_path):
    """
    æ£€æŸ¥camera.jsonæˆ–meta.jsonæ–‡ä»¶æ˜¯å¦æ­£å¸¸
    ä¸¤ç§æ–‡ä»¶å†…å®¹ç›¸åŒï¼Œåªæ˜¯å‘½åä¸åŒ
    """
    try:
        with open(camera_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥é”™è¯¯æ ‡è®°
        if 'cam_status' in data and data['cam_status'] == 'uninitialized':
            return {
                'valid': False,
                'reason': 'camera uninitialized',
                'file_type': 'camera/meta'
            }
        
        if 'err' in data:
            return {
                'valid': False,
                'reason': 'error in camera data',
                'error': data['err'],
                'file_type': 'camera/meta'
            }
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if 'extrinsic_cam2world' not in data:
            return {
                'valid': False,
                'reason': 'missing extrinsic_cam2world',
                'file_type': 'camera/meta'
            }
        
        return {
            'valid': True,
            'file_type': 'camera/meta'
        }
        
    except Exception as e:
        return {
            'valid': False,
            'reason': 'file read error',
            'error': str(e),
            'file_type': 'camera/meta'
        }


def validate_action_folder(action_dir, sample_rate=VALIDATION_SAMPLE_RATE):
    """
    éªŒè¯actionæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®è´¨é‡ï¼ˆå…¼å®¹cameraå’Œmetaï¼‰
    åªè¦å‘ç°ä¸€ä¸ªå¼‚å¸¸æ–‡ä»¶ï¼Œç«‹å³è¿”å›ä¸åˆæ ¼
    é‡‡ç”¨é‡‡æ ·æ£€æŸ¥ä»¥æé«˜é€Ÿåº¦
    """
    action_name = os.path.basename(action_dir)
    
    # æŸ¥æ‰¾æ‰€æœ‰depthæ–‡ä»¶
    depth_files = sorted(glob.glob(os.path.join(action_dir, "frame_*_depth.npy")))
    total_frames = len(depth_files)
    
    if total_frames == 0:
        return {
            'valid': False,
            'action_name': action_name,
            'reason': 'no_frames',
            'message': 'æœªæ‰¾åˆ°å¸§æ–‡ä»¶',
            'first_error_frame': None
        }
    
    # æ£€æµ‹ä½¿ç”¨çš„æ˜¯cameraè¿˜æ˜¯metaå‘½å
    camera_files = glob.glob(os.path.join(action_dir, "frame_*_camera.json"))
    meta_files = glob.glob(os.path.join(action_dir, "frame_*_meta.json"))
    
    if camera_files:
        file_type = "camera.json"
    elif meta_files:
        file_type = "meta.json"
    else:
        return {
            'valid': False,
            'action_name': action_name,
            'reason': 'no_camera_meta',
            'message': 'æœªæ‰¾åˆ°camera.jsonæˆ–meta.jsonæ–‡ä»¶',
            'first_error_frame': None
        }
    
    logger.log(f"   æ£€æµ‹åˆ°æ–‡ä»¶ç±»å‹: {file_type}")
    
    checked_count = 0
    
    # é‡‡æ ·æ£€æŸ¥ï¼ˆä¸€æ—¦å‘ç°å¼‚å¸¸ç«‹å³è¿”å›ï¼‰
    for i in range(0, total_frames, sample_rate):
        frame_idx = i
        depth_path = os.path.join(action_dir, f"frame_{frame_idx:06d}_depth.npy")
        camera_meta_path = find_camera_or_meta_file(action_dir, frame_idx)
        
        # æ£€æŸ¥depth
        if os.path.exists(depth_path):
            depth_result = check_depth_file(depth_path)
            if not depth_result['valid']:
                # å‘ç°å¼‚å¸¸ï¼Œç«‹å³è¿”å›
                error_detail = depth_result.get('error', 
                    f"mean={depth_result.get('mean', 0):.1f}, std={depth_result.get('std', 0):.1f}")
                return {
                    'valid': False,
                    'action_name': action_name,
                    'reason': 'depth_abnormal',
                    'message': f'å‘ç°depthå¼‚å¸¸æ–‡ä»¶',
                    'first_error_frame': frame_idx,
                    'error_type': 'depth',
                    'error_detail': error_detail,
                    'total_frames': total_frames,
                    'checked_frames': checked_count + 1
                }
        
        # æ£€æŸ¥camera/meta
        if camera_meta_path:
            camera_result = check_camera_file(camera_meta_path)
            if not camera_result['valid']:
                # å‘ç°å¼‚å¸¸ï¼Œç«‹å³è¿”å›
                return {
                    'valid': False,
                    'action_name': action_name,
                    'reason': 'camera_meta_abnormal',
                    'message': f'å‘ç°{file_type}å¼‚å¸¸æ–‡ä»¶',
                    'first_error_frame': frame_idx,
                    'error_type': file_type,
                    'error_detail': camera_result.get('reason', 'unknown') + 
                                   (f": {camera_result.get('error', '')}" if 'error' in camera_result else ''),
                    'total_frames': total_frames,
                    'checked_frames': checked_count + 1
                }
        else:
            # ç¼ºå¤±camera/metaæ–‡ä»¶
            return {
                'valid': False,
                'action_name': action_name,
                'reason': 'missing_camera_meta',
                'message': f'ç¼ºå¤±{file_type}æ–‡ä»¶',
                'first_error_frame': frame_idx,
                'error_type': file_type,
                'error_detail': 'æ–‡ä»¶ä¸å­˜åœ¨',
                'total_frames': total_frames,
                'checked_frames': checked_count + 1
            }
        
        checked_count += 1
    
    # å…¨éƒ¨æ£€æŸ¥é€šè¿‡
    return {
        'valid': True,
        'action_name': action_name,
        'total_frames': total_frames,
        'checked_frames': checked_count,
        'file_type': file_type,
        'message': 'æ•°æ®è´¨é‡æ­£å¸¸'
    }


# ==================== ä¸‹è½½æ¨¡å— ====================
def download_file(url, save_path):
    """ä¸‹è½½æ–‡ä»¶"""
    logger.log(f"å¼€å§‹ä¸‹è½½: {os.path.basename(save_path)}")
    
    try:
        if os.path.exists(save_path):
            logger.log(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            return True
        
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        with open(save_path, 'wb') as f, tqdm(
            desc=os.path.basename(save_path),
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
        ) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    pbar.update(len(chunk))
        
        logger.log(f"ä¸‹è½½å®Œæˆ: {os.path.basename(save_path)}")
        return True
        
    except Exception as e:
        logger.log(f"ä¸‹è½½å¤±è´¥: {str(e)}", "ERROR")
        if os.path.exists(save_path):
            os.remove(save_path)
        return False

def extract_filename_from_url(url):
    """ä»URLæå–æ–‡ä»¶å"""
    parsed = urlparse(url)
    filename = os.path.basename(parsed.path)
    filename = unquote(filename)
    return filename

# ==================== è§£å‹æ¨¡å— ====================
def normalize_folder_structure(folder_path):
    """è‡ªåŠ¨æ ‡å‡†åŒ–æ–‡ä»¶å¤¹ç»“æ„ï¼ˆå¤„ç†åµŒå¥—ï¼‰"""
    max_iterations = 3
    iteration = 0
    
    while iteration < max_iterations:
        iteration += 1
        items = os.listdir(folder_path)
        
        # æ£€æŸ¥æ˜¯å¦å·²æ­£å¸¸
        has_actions = any(item.startswith('actions_') for item in items 
                         if os.path.isdir(os.path.join(folder_path, item)))
        has_groups = any(item.startswith('group_') for item in items 
                        if os.path.isdir(os.path.join(folder_path, item)))
        
        if has_actions or has_groups:
            return True
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œå°è¯•æå‡
        folders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]
        
        if len(folders) == 1:
            single_folder = folders[0]
            single_folder_path = os.path.join(folder_path, single_folder)
            
            logger.log(f"æ£€æµ‹åˆ°åµŒå¥—æ–‡ä»¶å¤¹ï¼Œæå‡å±‚çº§: {single_folder}")
            
            sub_items = os.listdir(single_folder_path)
            
            for item in sub_items:
                src = os.path.join(single_folder_path, item)
                dst = os.path.join(folder_path, item)
                
                if os.path.exists(dst):
                    continue
                
                try:
                    shutil.move(src, dst)
                except Exception as e:
                    logger.log(f"ç§»åŠ¨å¤±è´¥ {item}: {str(e)}", "ERROR")
            
            # åˆ é™¤ç©ºæ–‡ä»¶å¤¹
            try:
                if not os.listdir(single_folder_path):
                    os.rmdir(single_folder_path)
            except:
                pass
            
            continue
        else:
            break
    
    # æœ€ç»ˆæ£€æŸ¥
    final_items = os.listdir(folder_path)
    has_actions = any(item.startswith('actions_') for item in final_items 
                     if os.path.isdir(os.path.join(folder_path, item)))
    has_groups = any(item.startswith('group_') for item in final_items 
                    if os.path.isdir(os.path.join(folder_path, item)))
    
    return has_actions or has_groups

def extract_zip(zip_path, extract_to):
    """è§£å‹ZIPå¹¶æ ‡å‡†åŒ–ç»“æ„"""
    logger.log(f"å¼€å§‹è§£å‹: {os.path.basename(zip_path)}")
    
    try:
        zip_basename = os.path.splitext(os.path.basename(zip_path))[0]
        target_folder = os.path.join(extract_to, zip_basename)
        
        os.makedirs(target_folder, exist_ok=True)
        
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(target_folder)
        
        logger.log(f"è§£å‹å®Œæˆï¼Œæ ‡å‡†åŒ–ç»“æ„ä¸­...")
        
        # æ ‡å‡†åŒ–ç»“æ„
        normalize_folder_structure(target_folder)
        
        # åˆ é™¤ZIP
        try:
            os.remove(zip_path)
            logger.log("å·²åˆ é™¤ZIPæ–‡ä»¶")
        except Exception as e:
            logger.log(f"åˆ é™¤ZIPå¤±è´¥: {str(e)}", "WARN")
        return target_folder
        
    except Exception as e:
        logger.log(f"è§£å‹å¤±è´¥: {str(e)}", "ERROR")
        return None

# ==================== æ•°æ®å¤„ç†æ¨¡å— ====================
def extract_rgb_from_video(video_path, output_dir):
    """æå–RGBå¸§"""
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        logger.log(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}", "ERROR")
        return 0
    
    total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    logger.log(f"æå–è§†é¢‘å¸§: {os.path.basename(video_path)} (å…±{total_video_frames}å¸§)")
    
    for frame_idx in tqdm(range(total_video_frames), desc="æå–RGBå¸§"):
        ret, bgr = cap.read()
        if not ret:
            continue
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(rgb)
        png_filename = os.path.join(output_dir, f"frame_{frame_idx:06d}_RGB.png")
        img.save(png_filename, format='PNG')
    
    cap.release()
    logger.log(f"RGBå¸§æå–å®Œæˆ")
    return total_video_frames

def split_frames_to_groups(action_dir, total_frames, group_size=GROUP_SIZE):
    """ç”Ÿæˆgroupï¼ˆå…¼å®¹cameraå’Œmetaï¼‰"""
    total_groups = ceil(total_frames / group_size)
    logger.log(f"åˆ†ç»„: {total_frames}å¸§ â†’ {total_groups}ç»„")
    
    action_basename = os.path.basename(action_dir)
    action_unique_id = action_basename.replace("actions_", "")
    group_info_list = []
    
    # æ£€æµ‹ä½¿ç”¨çš„æ–‡ä»¶ç±»å‹
    has_camera = os.path.exists(os.path.join(action_dir, "frame_000000_camera.json"))
    has_meta = os.path.exists(os.path.join(action_dir, "frame_000000_meta.json"))
    
    for group_idx in tqdm(range(total_groups), desc="ç”Ÿæˆgroup"):
        start_frame = group_idx * group_size
        end_frame = min((group_idx + 1) * group_size - 1, total_frames - 1)
        group_unique_name = f"group_{action_unique_id}_{group_idx + 1:03d}"
        temp_group_path = os.path.join(action_dir, group_unique_name)
        os.makedirs(temp_group_path, exist_ok=True)
        
        for frame_idx in range(start_frame, end_frame + 1):
            frame_prefix = f"frame_{frame_idx:06d}"
            
            # åŸºç¡€æ–‡ä»¶
            files_to_copy = [
                f"{frame_prefix}_RGB.png",
                f"{frame_prefix}_depth.npy"
            ]
            
            # æ·»åŠ cameraæˆ–metaæ–‡ä»¶
            if has_camera:
                files_to_copy.append(f"{frame_prefix}_camera.json")
            if has_meta:
                files_to_copy.append(f"{frame_prefix}_meta.json")
            
            # å¤åˆ¶æ–‡ä»¶
            for filename in files_to_copy:
                src = os.path.join(action_dir, filename)
                dst = os.path.join(temp_group_path, filename)
                if os.path.exists(src):
                    shutil.copy2(src, dst)
        
        group_info_list.append((temp_group_path, group_unique_name))
    
    logger.log(f"åˆ†ç»„å®Œæˆ: {len(group_info_list)}ä¸ªgroup")
    return group_info_list

def move_single_action_groups(group_info_list, root_dir, action_dir):
    """ç§»åŠ¨groupåˆ°æ ¹ç›®å½•"""
    success_count = 0
    all_moved = True
    
    for temp_group_path, group_unique_name in tqdm(group_info_list, desc="ç§»åŠ¨group"):
        target_group_path = os.path.join(root_dir, group_unique_name)
        
        try:
            if os.path.exists(target_group_path):
                all_moved = False
                continue
            
            shutil.move(temp_group_path, target_group_path)
            if os.path.exists(target_group_path):
                success_count += 1
            else:
                all_moved = False
        except Exception as e:
            logger.log(f"ç§»åŠ¨groupå¤±è´¥: {str(e)}", "ERROR")
            all_moved = False
    
    logger.log(f"groupç§»åŠ¨å®Œæˆ: {success_count}ä¸ªæˆåŠŸ")
    return all_moved

def delete_action_folder(action_dir):
    """åˆ é™¤actionæ–‡ä»¶å¤¹"""
    try:
        shutil.rmtree(action_dir)
        if not os.path.exists(action_dir):
            return True
        return False
    except Exception as e:
        logger.log(f"åˆ é™¤actionæ–‡ä»¶å¤¹å¤±è´¥: {str(e)}", "ERROR")
        return False

def process_single_action(action_dir, root_dir):
    """
    å¤„ç†å•ä¸ªactionï¼ˆå…¼å®¹cameraå’Œmetaï¼Œé›¶å®¹å¿ï¼‰
    è¿”å›: True=æˆåŠŸ, False=å¤±è´¥, None=è·³è¿‡ï¼ˆæ•°æ®è´¨é‡é—®é¢˜ï¼‰
    """
    action_name = os.path.basename(action_dir)
    logger.log(f"å¤„ç†action: {action_name}")
    
    # æ­¥éª¤1: éªŒè¯æ•°æ®è´¨é‡ï¼ˆé›¶å®¹å¿ï¼‰
    logger.log(f"éªŒè¯æ•°æ®è´¨é‡ï¼ˆé‡‡æ ·ç‡: æ¯{VALIDATION_SAMPLE_RATE}å¸§ï¼‰...")
    validation_result = validate_action_folder(action_dir)
    
    if not validation_result['valid']:
        # å‘ç°å¼‚å¸¸æ–‡ä»¶ï¼Œè‡ªåŠ¨è·³è¿‡æ•´ä¸ªaction
        error_frame = validation_result.get('first_error_frame')
        error_type = validation_result.get('error_type', 'unknown')
        error_detail = validation_result.get('error_detail', '')
        
        skip_message = (
            f"å‘ç°å¼‚å¸¸æ–‡ä»¶ï¼Œè·³è¿‡æ•´ä¸ªaction\n"
            f"      æ€»å¸§æ•°: {validation_result.get('total_frames', 0)}\n"
            f"      å·²æ£€æŸ¥: {validation_result.get('checked_frames', 0)} å¸§\n"
            f"      å¼‚å¸¸å¸§: frame_{error_frame:06d} (å¦‚æœæœ‰)\n"
            f"      å¼‚å¸¸ç±»å‹: {error_type}\n"
            f"      è¯¦ç»†ä¿¡æ¯: {error_detail}"
        )
        
        logger.log(f"âŒ {skip_message}", "SKIP")
        logger.log_skipped_action(
            action_name,
            validation_result.get('reason', 'unknown'),
            skip_message
        )
        logger.stats['actions_skipped'] += 1
        return None  # è¿”å›Noneè¡¨ç¤ºè·³è¿‡
    
    file_type = validation_result.get('file_type', 'camera.json')
    logger.log(f"âœ… æ•°æ®è´¨é‡éªŒè¯é€šè¿‡ï¼ˆæ£€æŸ¥äº†{validation_result['checked_frames']}å¸§ï¼Œæ–‡ä»¶ç±»å‹: {file_type}ï¼‰")
    
    # æ­¥éª¤2: æ£€æŸ¥è§†é¢‘æ–‡ä»¶
    video_path = os.path.join(action_dir, "capture.mp4")
    if not os.path.exists(video_path):
        logger.log(f"æœªæ‰¾åˆ°capture.mp4", "WARN")
        return False
    
    # æ­¥éª¤3: æå–RGBå¸§
    total_frames = extract_rgb_from_video(video_path, action_dir)
    if total_frames == 0:
        logger.log(f"è§†é¢‘å¸§æå–å¤±è´¥", "ERROR")
        return False
    
    # æ­¥éª¤4: ç”Ÿæˆgroup
    group_info_list = split_frames_to_groups(action_dir, total_frames)
    
    # æ­¥éª¤5: åˆ é™¤åŸå§‹æ•°æ®ï¼ˆå…¼å®¹cameraå’Œmetaï¼‰
    logger.log(f"åˆ é™¤åŸå§‹æ•°æ®...")
    if os.path.exists(video_path):
        os.remove(video_path)
    
    # æ£€æµ‹æ–‡ä»¶ç±»å‹
    has_camera = os.path.exists(os.path.join(action_dir, "frame_000000_camera.json"))
    has_meta = os.path.exists(os.path.join(action_dir, "frame_000000_meta.json"))
    
    for frame_idx in range(total_frames):
        frame_prefix = f"frame_{frame_idx:06d}"
        files_to_delete = [
            f"{frame_prefix}_RGB.png",
            f"{frame_prefix}_depth.npy"
        ]
        
        # æ·»åŠ cameraæˆ–metaæ–‡ä»¶
        if has_camera:
            files_to_delete.append(f"{frame_prefix}_camera.json")
        if has_meta:
            files_to_delete.append(f"{frame_prefix}_meta.json")
        
        for filename in files_to_delete:
            file_path = os.path.join(action_dir, filename)
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
    
    # æ­¥éª¤6: ç§»åŠ¨group
    all_groups_moved = move_single_action_groups(group_info_list, root_dir, action_dir)
    
    # æ­¥éª¤7: åˆ é™¤actionæ–‡ä»¶å¤¹
    if all_groups_moved:
        delete_action_folder(action_dir)
    
    logger.stats['actions_processed'] += 1
    return True

def process_extracted_folder(folder_path):
    """
    å¤„ç†è§£å‹åçš„æ–‡ä»¶å¤¹ï¼ˆå…¨è‡ªåŠ¨ï¼Œé›¶å®¹å¿ï¼‰
    """
    logger.log(f"å¤„ç†æ–‡ä»¶å¤¹: {os.path.basename(folder_path)}")
    
    # æŸ¥æ‰¾æ‰€æœ‰actions
    action_dirs = sorted(glob.glob(os.path.join(folder_path, "actions_*")))
    
    if not action_dirs:
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯groupæ ¼å¼
        group_dirs = glob.glob(os.path.join(folder_path, "group_*"))
        if group_dirs:
            logger.log(f"å‘ç°{len(group_dirs)}ä¸ªgroupï¼Œæ•°æ®å·²å¤„ç†å¥½")
            return True
        
        logger.log(f"æœªæ‰¾åˆ°actionsæˆ–groupæ–‡ä»¶å¤¹", "WARN")
        return False
    
    logger.log(f"æ‰¾åˆ°{len(action_dirs)}ä¸ªactions")
    logger.stats['actions_total'] += len(action_dirs)
    
    success_count = 0
    skipped_count = 0
    failed_count = 0
    
    for action_dir in action_dirs:
        logger.log(f"\n{'â”€'*60}")
        result = process_single_action(action_dir, folder_path)
        
        if result is True:
            success_count += 1
            logger.log(f"âœ… Actionå¤„ç†æˆåŠŸ: {os.path.basename(action_dir)}")
        elif result is None:
            skipped_count += 1
            logger.log(f"â­ï¸ Actionå·²è·³è¿‡: {os.path.basename(action_dir)}")
        else:
            failed_count += 1
            logger.log(f"âŒ Actionå¤„ç†å¤±è´¥: {os.path.basename(action_dir)}")
    
    logger.log(f"\n{'â”€'*60}")
    logger.log(f"æ–‡ä»¶å¤¹å¤„ç†æ±‡æ€»:")
    logger.log(f"  âœ… æˆåŠŸ: {success_count}/{len(action_dirs)}")
    logger.log(f"  â­ï¸ è·³è¿‡: {skipped_count}/{len(action_dirs)}")
    logger.log(f"  âŒ å¤±è´¥: {failed_count}/{len(action_dirs)}")
    logger.log(f"{'â”€'*60}")
    
    # åªè¦æœ‰æˆåŠŸçš„å°±ç®—æˆåŠŸ
    return success_count > 0

# ==================== OSSä¸Šä¼ æ¨¡å— ====================
def get_game_name_from_folder(folder_name):
    """æå–æ¸¸æˆåç§°"""
    game_name = folder_name.split('-')[0]
    return game_name

def upload_tmp_to_oss(tmp_path, oss_base_path):
    """ä¸Šä¼ tmpåˆ°OSS"""
    logger.log("å¼€å§‹ä¸Šä¼ åˆ°OSS")
    
    subfolders = [f for f in os.listdir(tmp_path) 
                  if os.path.isdir(os.path.join(tmp_path, f)) and f != 'logs']
    
    if not subfolders:
        logger.log("tmpæ–‡ä»¶å¤¹ä¸ºç©º", "WARN")
        return True
    
    first_folder = subfolders[0]
    game_name = get_game_name_from_folder(first_folder)
    oss_target_path = f"{oss_base_path}{game_name}/"
    
    logger.log(f"æœ¬åœ°: {tmp_path}")
    logger.log(f"OSS: {oss_target_path}")
    logger.log(f"æ¸¸æˆ: {game_name}")
    
    # ç»Ÿè®¡æ–‡ä»¶
    total_files = 0
    total_size = 0
    for folder in subfolders:
        folder_path = os.path.join(tmp_path, folder)
        for root, dirs, files in os.walk(folder_path):
            total_files += len(files)
            for file in files:
                try:
                    total_size += os.path.getsize(os.path.join(root, file))
                except:
                    pass
    
    logger.log(f"æ–‡ä»¶æ•°: {total_files:,}, å¤§å°: {total_size / (1024**3):.2f} GB")
    
    try:
        cmd = [
            OSSUTIL_PATH,
            'cp',
            '-r',
            '-u',
            '--jobs', '3',
            tmp_path,
            oss_target_path
        ]
        
        logger.log(f"æ‰§è¡Œä¸Šä¼ å‘½ä»¤...")
        
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',
            errors='ignore',
            bufsize=1
        )
        
        for line in process.stdout:
            line = line.strip()
            if line:
                print(f"   {line}")
        
        return_code = process.wait()
        
        if return_code == 0:
            logger.log("ä¸Šä¼ æˆåŠŸ")
            return True
        else:
            logger.log(f"ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›ç : {return_code}", "ERROR")
            return False
            
    except FileNotFoundError:
        logger.log(f"æ‰¾ä¸åˆ°ossutil: {OSSUTIL_PATH}", "ERROR")
        return False
    except Exception as e:
        logger.log(f"ä¸Šä¼ å‡ºé”™: {str(e)}", "ERROR")
        return False

# ==================== æ¸…ç†æ¨¡å— ====================
def cleanup_tmp_folder(tmp_path):
    """æ¸…ç©ºtmpï¼ˆä¿ç•™logsï¼‰"""
    logger.log("æ¸…ç†tmpæ–‡ä»¶å¤¹")
    
    try:
        for item in os.listdir(tmp_path):
            if item == 'logs':  # ä¿ç•™æ—¥å¿—æ–‡ä»¶å¤¹
                continue
            
            item_path = os.path.join(tmp_path, item)
            
            if os.path.isdir(item_path):
                shutil.rmtree(item_path)
            else:
                os.remove(item_path)
        
        remaining = [f for f in os.listdir(tmp_path) if f != 'logs']
        if not remaining:
            logger.log("tmpå·²æ¸…ç©º")
            return True
        else:
            logger.log(f"ä»æœ‰{len(remaining)}ä¸ªé¡¹ç›®æœªåˆ é™¤", "WARN")
            return False
            
    except Exception as e:
        logger.log(f"æ¸…ç†å‡ºé”™: {str(e)}", "ERROR")
        return False

# ==================== ä¸»æµç¨‹ ====================
def process_single_url(url, tmp_dir, oss_base_path):
    """å¤„ç†å•ä¸ªURLï¼ˆå…¨è‡ªåŠ¨ï¼‰"""
    logger.log("\n" + "#" * 60)
    logger.log("å¼€å§‹å¤„ç†æ–°çš„æ•°æ®åŒ…")
    logger.log("#" * 60)
    
    # ä¸‹è½½
    filename = extract_filename_from_url(url)
    zip_path = os.path.join(tmp_dir, filename)
    
    if not download_file(url, zip_path):
        return False
    
    # è§£å‹
    extracted_folder = extract_zip(zip_path, tmp_dir)
    if not extracted_folder or not os.path.exists(extracted_folder):
        return False
    
    # å¤„ç†ï¼ˆè‡ªåŠ¨éªŒè¯å’Œè·³è¿‡å¼‚å¸¸ï¼‰
    try:
        process_result = process_extracted_folder(extracted_folder)
        if not process_result:
            logger.log("å¤„ç†å¤±è´¥æˆ–å…¨éƒ¨è·³è¿‡", "WARN")
            # è‡ªåŠ¨æ¸…ç†å¤±è´¥çš„æ•°æ®
            cleanup_tmp_folder(tmp_dir)
            return False
    except Exception as e:
        logger.log(f"å¤„ç†å‡ºé”™: {str(e)}", "ERROR")
        import traceback
        traceback.print_exc()
        cleanup_tmp_folder(tmp_dir)
        return False
    
    # ä¸Šä¼ 
    if not upload_tmp_to_oss(tmp_dir, oss_base_path):
        logger.log("ä¸Šä¼ å¤±è´¥ï¼Œä¿ç•™æœ¬åœ°æ–‡ä»¶", "ERROR")
        return False
    
    # æ¸…ç†
    cleanup_tmp_folder(tmp_dir)
    
    logger.log("#" * 60)
    logger.log("æ•°æ®åŒ…å¤„ç†å®Œæˆ")
    logger.log("#" * 60 + "\n")
    
    return True

def main():
    parser = argparse.ArgumentParser(
        description="è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµç¨‹ï¼ˆé›¶å®¹å¿ç‰ˆæœ¬ï¼‰ï¼šå‘ç°å¼‚å¸¸ç«‹å³è·³è¿‡action",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š
  python script.py urls.txt
  python script.py urls.txt --start-from 5
  python script.py urls.txt --sample-rate 20  # åŠ å¿«éªŒè¯é€Ÿåº¦
  
ç‰¹æ€§ï¼š
  - å…¨è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€äººå·¥å¹²é¢„
  - é›¶å®¹å¿ç­–ç•¥ï¼šå‘ç°ä»»ä½•å¼‚å¸¸æ–‡ä»¶ç«‹å³è·³è¿‡æ•´ä¸ªaction
  - é‡‡æ ·éªŒè¯ï¼šæ¯Nå¸§æ£€æŸ¥ä¸€æ¬¡ï¼Œæé«˜å¤„ç†é€Ÿåº¦
  - å¼‚å¸¸actionä¸ä¸Šä¼ ï¼Œä½†ä¼šç»§ç»­å¤„ç†å…¶ä»–action
  - è¯¦ç»†æ—¥å¿—è®°å½•æ‰€æœ‰è·³è¿‡çš„action
        """
    )
    parser.add_argument(
        "url_file",
        help="åŒ…å«ä¸‹è½½é“¾æ¥çš„æ–‡æœ¬æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--start-from",
        type=int,
        default=1,
        help="ä»ç¬¬å‡ ä¸ªURLå¼€å§‹å¤„ç†ï¼ˆé»˜è®¤ä»ç¬¬1ä¸ªå¼€å§‹ï¼‰"
    )
    parser.add_argument(
        "--skip-upload",
        action="store_true",
        help="è·³è¿‡ä¸Šä¼ æ­¥éª¤ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--sample-rate",
        type=int,
        default=10,  # ç›´æ¥ä½¿ç”¨æ•°å€¼ï¼Œä¸å¼•ç”¨å…¨å±€å˜é‡
        help=f"éªŒè¯é‡‡æ ·ç‡ï¼šæ¯Nå¸§æ£€æŸ¥ä¸€æ¬¡ï¼ˆé»˜è®¤10ï¼‰"
    )
    
    args = parser.parse_args()
    
    # å…ˆå£°æ˜å…¨å±€å˜é‡ï¼Œå†ä¿®æ”¹
    global logger, VALIDATION_SAMPLE_RATE
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = ProcessLogger(LOG_DIR)
    
    # æ›´æ–°å…¨å±€é…ç½®
    VALIDATION_SAMPLE_RATE = args.sample_rate
    
    # è¯»å–URLåˆ—è¡¨
    if not os.path.exists(args.url_file):
        print(f"âŒ URLæ–‡ä»¶ä¸å­˜åœ¨: {args.url_file}")
        return
    
    try:
        with open(args.url_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except Exception as e:
        print(f"âŒ è¯»å–URLæ–‡ä»¶å¤±è´¥: {str(e)}")
        return
    
    if not urls:
        print(f"âŒ URLæ–‡ä»¶ä¸ºç©º")
        return
    
    # åˆ›å»ºç›®å½•
    os.makedirs(BASE_DIR, exist_ok=True)
    
    # æ˜¾ç¤ºé…ç½®
    logger.log("="*60)
    logger.log("è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµç¨‹ï¼ˆé›¶å®¹å¿ç‰ˆæœ¬ï¼‰")
    logger.log("="*60)
    logger.log(f"å·¥ä½œç›®å½•: {BASE_DIR}")
    logger.log(f"OSSè·¯å¾„: {OSS_BASE_PATH}")
    logger.log(f"æ€»URLæ•°: {len(urls)}")
    logger.log(f"å¼€å§‹ä½ç½®: ç¬¬{args.start_from}ä¸ª")
    logger.log(f"éªŒè¯é‡‡æ ·ç‡: æ¯{VALIDATION_SAMPLE_RATE}å¸§")
    logger.log(f"éªŒè¯ç­–ç•¥: é›¶å®¹å¿ï¼ˆå‘ç°ä»»ä½•å¼‚å¸¸ç«‹å³è·³è¿‡actionï¼‰")
    logger.log(f"æ—¥å¿—ç›®å½•: {LOG_DIR}")
    if args.skip_upload:
        logger.log("âš ï¸ æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡ä¸Šä¼ ")
    logger.log("="*60)
    
    # ç»Ÿè®¡
    logger.stats['total_urls'] = len(urls)
    failed_urls = []
    
    # å¼€å§‹å¤„ç†
    try:
        for idx, url in enumerate(urls, 1):
            if idx < args.start_from:
                logger.log(f"â­ï¸ è·³è¿‡ç¬¬{idx}ä¸ªURL")
                continue
            
            logger.log(f"\n{'='*60}")
            logger.log(f"[æ€»è¿›åº¦: {idx}/{len(urls)}] å¤„ç†ç¬¬{idx}ä¸ªURL")
            logger.log(f"{'='*60}")
            
            filename = extract_filename_from_url(url)
            logger.log(f"æ–‡ä»¶: {filename}")
            
            try:
                if args.skip_upload:
                    # æµ‹è¯•æ¨¡å¼
                    zip_path = os.path.join(BASE_DIR, filename)
                    if download_file(url, zip_path):
                        extracted_folder = extract_zip(zip_path, BASE_DIR)
                        if extracted_folder:
                            if process_extracted_folder(extracted_folder):
                                logger.stats['success'] += 1
                                logger.log(f"âœ… ç¬¬{idx}ä¸ªURLå¤„ç†æˆåŠŸï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
                            else:
                                logger.stats['failed'] += 1
                                failed_urls.append((idx, url))
                        else:
                            logger.stats['failed'] += 1
                            failed_urls.append((idx, url))
                    else:
                        logger.stats['failed'] += 1
                        failed_urls.append((idx, url))
                else:
                    # æ­£å¸¸æ¨¡å¼
                    if process_single_url(url, BASE_DIR, OSS_BASE_PATH):
                        logger.stats['success'] += 1
                        logger.log(f"âœ… ç¬¬{idx}ä¸ªURLå¤„ç†æˆåŠŸ")
                    else:
                        logger.stats['failed'] += 1
                        failed_urls.append((idx, url))
                        logger.log_error(idx, url, "å¤„ç†æµç¨‹å¤±è´¥")
                
            except KeyboardInterrupt:
                raise
            except Exception as e:
                logger.stats['failed'] += 1
                failed_urls.append((idx, url))
                logger.log_error(idx, url, str(e))
                import traceback
                traceback.print_exc()
            
            # å½“å‰è¿›åº¦
            logger.log(f"\nğŸ“Š å½“å‰è¿›åº¦: "
                      f"æˆåŠŸ{logger.stats['success']}ä¸ª, "
                      f"å¤±è´¥{logger.stats['failed']}ä¸ª, "
                      f"å‰©ä½™{len(urls) - idx}ä¸ª")
    
    except KeyboardInterrupt:
        logger.log("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ", "WARN")
        logger.log(f"å·²å¤„ç†: {idx - 1}/{len(urls)}")
    
    # æœ€ç»ˆç»Ÿè®¡
    logger.summary()
    
    if failed_urls:
        logger.log(f"\nâŒ å¤±è´¥çš„URLåˆ—è¡¨:")
        for idx, url in failed_urls:
            filename = extract_filename_from_url(url)
            logger.log(f"   [{idx}] {filename}")
        
        # ä¿å­˜å¤±è´¥åˆ—è¡¨
        failed_file = os.path.join(LOG_DIR, "failed_urls.txt")
        try:
            with open(failed_file, 'w', encoding='utf-8') as f:
                for idx, url in failed_urls:
                    f.write(f"{url}\n")
            logger.log(f"\nğŸ’¾ å¤±è´¥URLå·²ä¿å­˜åˆ°: {failed_file}")
        except Exception as e:
            logger.log(f"ä¿å­˜å¤±è´¥åˆ—è¡¨å‡ºé”™: {str(e)}", "ERROR")
    
    logger.log(f"\nğŸ“ æ—¥å¿—æ–‡ä»¶:")
    logger.log(f"   å®Œæ•´æ—¥å¿—: {logger.log_file}")
    logger.log(f"   é”™è¯¯æ—¥å¿—: {logger.error_file}")
    logger.log(f"   è·³è¿‡è®°å½•: {logger.skipped_file}")


if __name__ == '__main__':
    main()
