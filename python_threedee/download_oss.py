#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµç¨‹ï¼ˆä¸²è¡Œç‰ˆæœ¬ï¼‰ï¼š
é€ä¸ªå¤„ç†ï¼šä¸‹è½½ â†’ è§£å‹ â†’ å¤„ç† â†’ ä¸Šä¼ OSS â†’ æ¸…ç† â†’ ä¸‹ä¸€ä¸ª
"""
import os
import sys
import cv2
import glob
import shutil
import zipfile
import subprocess
import requests
import argparse
from pathlib import Path
from tqdm import tqdm
from math import ceil
from PIL import Image
from urllib.parse import urlparse, unquote

# ==================== é…ç½®å‚æ•° ====================
BASE_DIR = r"C:\Users\10762\Desktop\data\tmp"
OSS_BASE_PATH = "oss://antsys-robbyh20-b1/cyh/game_data/"  # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
OSSUTIL_PATH = "ossutil"  # å¦‚æœossutilä¸åœ¨PATHä¸­ï¼Œè¯·ä¿®æ”¹ä¸ºå®Œæ•´è·¯å¾„
GROUP_SIZE = 100  # æ¯ç»„å¸§æ•°

# ==================== ä¸‹è½½æ¨¡å— ====================
def download_file(url, save_path):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
    print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½: {os.path.basename(save_path)}")
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(save_path):
            existing_size = os.path.getsize(save_path)
            print(f"   âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤§å°: {existing_size / (1024**2):.2f}MB")
            confirm = input(f"   æ˜¯å¦é‡æ–°ä¸‹è½½ï¼Ÿ(y/n): ")
            if confirm.lower() != 'y':
                print(f"   âœ… ä½¿ç”¨å·²å­˜åœ¨æ–‡ä»¶")
                return True
            os.remove(save_path)
        
        # å‘èµ·ä¸‹è½½è¯·æ±‚
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        # ä½¿ç”¨è¿›åº¦æ¡ä¸‹è½½
        with open(save_path, 'wb') as f, tqdm(
            desc=os.path.basename(save_path),
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
        ) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    pbar.update(len(chunk))
        
        print(f"âœ… ä¸‹è½½å®Œæˆ: {os.path.basename(save_path)}")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        if os.path.exists(save_path):
            os.remove(save_path)
        return False

def extract_filename_from_url(url):
    """ä»URLä¸­æå–æ–‡ä»¶åï¼ˆå¤„ç†URLç¼–ç ï¼‰"""
    parsed = urlparse(url)
    filename = os.path.basename(parsed.path)
    filename = unquote(filename)
    return filename

# ==================== è§£å‹æ¨¡å— ====================
def extract_zip(zip_path, extract_to):
    """
    è§£å‹ZIPæ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
    ç¡®ä¿è§£å‹åçš„ç»“æ„ä¸ºï¼šextract_to/å‹ç¼©åŒ…åï¼ˆä¸å«.zipï¼‰/actions_xxx/
    """
    print(f"\nğŸ“¦ å¼€å§‹è§£å‹: {os.path.basename(zip_path)}")
    
    try:
        # è·å–å‹ç¼©åŒ…åç§°ï¼ˆä¸å«.zipï¼‰
        zip_basename = os.path.splitext(os.path.basename(zip_path))[0]
        target_folder = os.path.join(extract_to, zip_basename)
        
        # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
        os.makedirs(target_folder, exist_ok=True)
        
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # è§£å‹åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
            zip_ref.extractall(target_folder)
        
        print(f"âœ… è§£å‹å®Œæˆ: {zip_basename}")
        print(f"   è§£å‹è·¯å¾„: {target_folder}")
        
        # åˆ é™¤ZIPæ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
        try:
            os.remove(zip_path)
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤ZIPæ–‡ä»¶")
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤ZIPå¤±è´¥: {str(e)}")
        
        return target_folder
        
    except Exception as e:
        print(f"âŒ è§£å‹å¤±è´¥: {str(e)}")
        return None

# ==================== æ•°æ®å¤„ç†æ¨¡å— ====================
def extract_rgb_from_video(video_path, output_dir):
    """æå–RGBå¸§"""
    os.makedirs(output_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return 0
    
    total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"ğŸ¥ æ­£åœ¨æå–è§†é¢‘å¸§: {os.path.basename(video_path)} (å…±{total_video_frames}å¸§)")
    
    for frame_idx in tqdm(range(total_video_frames), desc="æå–RGBå¸§"):
        ret, bgr = cap.read()
        if not ret:
            print(f"âš ï¸ è·³è¿‡ç¬¬{frame_idx}å¸§ï¼ˆè¯»å–å¤±è´¥ï¼‰")
            continue
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(rgb)
        png_filename = os.path.join(output_dir, f"frame_{frame_idx:06d}_RGB.png")
        img.save(png_filename, format='PNG')
    
    cap.release()
    print(f"âœ… RGBå¸§æå–å®Œæˆï¼Œå…±{total_video_frames}å¸§")
    return total_video_frames

def split_frames_to_groups(action_dir, total_frames, group_size=GROUP_SIZE):
    """ç”Ÿæˆä¸´æ—¶group"""
    total_groups = ceil(total_frames / group_size)
    print(f"ğŸ“¦ å¼€å§‹åˆ†ç»„ï¼šå…±{total_frames}å¸§ â†’ åˆ†{total_groups}ç»„ï¼ˆæ¯ç»„{group_size}å¸§ï¼‰")
    
    action_basename = os.path.basename(action_dir)
    action_unique_id = action_basename.replace("actions_", "")
    group_info_list = []
    
    for group_idx in tqdm(range(total_groups), desc="ç”Ÿæˆä¸´æ—¶group"):
        start_frame = group_idx * group_size
        end_frame = min((group_idx + 1) * group_size - 1, total_frames - 1)
        group_unique_name = f"group_{action_unique_id}_{group_idx + 1:03d}"
        temp_group_path = os.path.join(action_dir, group_unique_name)
        os.makedirs(temp_group_path, exist_ok=True)
        
        for frame_idx in range(start_frame, end_frame + 1):
            frame_prefix = f"frame_{frame_idx:06d}"
            files_to_copy = [f"{frame_prefix}_RGB.png", f"{frame_prefix}_depth.npy", f"{frame_prefix}_camera.json"]
            for filename in files_to_copy:
                src = os.path.join(action_dir, filename)
                dst = os.path.join(temp_group_path, filename)
                if os.path.exists(src):
                    shutil.copy2(src, dst)
        
        group_info_list.append((temp_group_path, group_unique_name))
    
    print(f"âœ… ä¸´æ—¶åˆ†ç»„å®Œæˆï¼å½“å‰actionå…±ç”Ÿæˆ{len(group_info_list)}ä¸ªgroup")
    return group_info_list

def move_single_action_groups(group_info_list, root_dir, action_dir):
    """ç§»åŠ¨å½“å‰actionçš„groupåˆ°æ ¹ç›®å½•"""
    print(f"\nğŸ“¤ å¼€å§‹ç§»åŠ¨{os.path.basename(action_dir)}çš„groupåˆ°æ ¹ç›®å½•")
    success_count = 0
    all_moved = True
    
    for temp_group_path, group_unique_name in tqdm(group_info_list, desc="ç§»åŠ¨group"):
        target_group_path = os.path.join(root_dir, group_unique_name)
        
        try:
            if os.path.exists(target_group_path):
                print(f"   âš ï¸ ç›®æ ‡groupå·²å­˜åœ¨ï¼Œè·³è¿‡ï¼š{group_unique_name}")
                all_moved = False
                continue
            
            shutil.move(temp_group_path, target_group_path)
            if os.path.exists(target_group_path):
                success_count += 1
            else:
                all_moved = False
        except Exception as e:
            print(f"   âŒ ç§»åŠ¨æŠ¥é”™ï¼š{str(e)}")
            all_moved = False
    
    print(f"\nğŸ“Š å½“å‰action groupç§»åŠ¨ç»Ÿè®¡ï¼šæˆåŠŸ{success_count}ä¸ª")
    return all_moved

def delete_action_folder(action_dir):
    """åˆ é™¤actionæ–‡ä»¶å¤¹"""
    print(f"\nğŸ—‘ï¸ å¼€å§‹åˆ é™¤actionæ–‡ä»¶å¤¹ï¼š{os.path.basename(action_dir)}")
    try:
        shutil.rmtree(action_dir)
        if not os.path.exists(action_dir):
            print(f"âœ… æˆåŠŸåˆ é™¤actionæ–‡ä»¶å¤¹")
            return True
        else:
            print(f"âŒ åˆ é™¤å¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ åˆ é™¤æŠ¥é”™ï¼š{str(e)}")
        return False

def process_single_action(action_dir, root_dir):
    """å¤„ç†å•ä¸ªaction"""
    action_name = os.path.basename(action_dir)
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ å¼€å§‹å¤„ç†actionï¼š{action_name}")
    print(f"{'='*60}")
    
    video_path = os.path.join(action_dir, "capture.mp4")
    if not os.path.exists(video_path):
        print(f"   âŒ æœªæ‰¾åˆ°capture.mp4ï¼Œè·³è¿‡è¯¥action")
        return False
    
    # æå–RGBå¸§
    total_frames = extract_rgb_from_video(video_path, action_dir)
    if total_frames == 0:
        return False
    
    # ç”Ÿæˆä¸´æ—¶group
    group_info_list = split_frames_to_groups(action_dir, total_frames)
    
    # åˆ é™¤åŸå§‹æ•°æ®
    print(f"\nğŸ—‘ï¸ åˆ é™¤åŸå§‹æ•°æ®")
    if os.path.exists(video_path):
        os.remove(video_path)
        print(f"   âœ… å·²åˆ é™¤è§†é¢‘æ–‡ä»¶")
    
    for frame_idx in tqdm(range(total_frames), desc="åˆ é™¤æœªåˆ†ç»„å¸§"):
        frame_prefix = f"frame_{frame_idx:06d}"
        files_to_delete = [f"{frame_prefix}_RGB.png", f"{frame_prefix}_depth.npy", f"{frame_prefix}_camera.json"]
        for filename in files_to_delete:
            file_path = os.path.join(action_dir, filename)
            if os.path.exists(file_path):
                os.remove(file_path)
    
    # ç§»åŠ¨group
    all_groups_moved = move_single_action_groups(group_info_list, root_dir, action_dir)
    
    # åˆ é™¤actionæ–‡ä»¶å¤¹
    if all_groups_moved:
        delete_action_folder(action_dir)
    
    return True

def process_extracted_folder(folder_path):
    """å¤„ç†è§£å‹åçš„æ–‡ä»¶å¤¹ï¼ˆå¤„ç†æ‰€æœ‰actionsï¼‰"""
    print(f"\n{'='*60}")
    print(f"âš™ï¸ å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹: {os.path.basename(folder_path)}")
    print(f"{'='*60}")
    
    # æŸ¥æ‰¾æ‰€æœ‰actionsæ–‡ä»¶å¤¹
    action_dirs = sorted(glob.glob(os.path.join(folder_path, "actions_*")))
    
    if not action_dirs:
        print(f"âš ï¸ æœªæ‰¾åˆ°actions_å¼€å¤´çš„æ–‡ä»¶å¤¹")
        return False
    
    print(f"ğŸ“‹ æ‰¾åˆ°{len(action_dirs)}ä¸ªactionsæ–‡ä»¶å¤¹")
    
    processed_count = 0
    for action_dir in action_dirs:
        if process_single_action(action_dir, folder_path):
            processed_count += 1
    
    print(f"\nâœ… æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼šæˆåŠŸå¤„ç†{processed_count}/{len(action_dirs)}ä¸ªaction")
    return processed_count > 0

# ==================== OSSä¸Šä¼ æ¨¡å— ====================
# ==================== OSSä¸Šä¼ æ¨¡å—ï¼ˆä¿®æ”¹ç‰ˆï¼‰====================
# ==================== OSSä¸Šä¼ æ¨¡å—ï¼ˆå¸¦è¿›åº¦æ¡ç‰ˆæœ¬ï¼‰====================
def get_game_name_from_folder(folder_name):
    """ä»æ–‡ä»¶å¤¹åç§°æå–æ¸¸æˆåç§°"""
    # å‡è®¾æ ¼å¼ä¸ºï¼šæ¸¸æˆå-æ—¥æœŸ-å…¶ä»–ä¿¡æ¯
    # ä¾‹å¦‚ï¼šèµ›åšæœ‹å…‹2077-20251016-F9-02-zzx
    game_name = folder_name.split('-')[0]
    return game_name

def upload_tmp_to_oss(tmp_path, oss_base_path):
    # """
    # ç›´æ¥ä¸Šä¼ æ•´ä¸ªtmpæ–‡ä»¶å¤¹åˆ°OSSï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
    # tmp_path: C:\Users\10762\Desktop\data\tmp\
    # ä¸Šä¼ åˆ°: oss://bucket/cyh/game_data/æ¸¸æˆå/
    
    # OSSæœ€ç»ˆç»“æ„ï¼š
    # oss://bucket/cyh/game_data/èµ›åšæœ‹å…‹2077/
    #     â”œâ”€â”€ èµ›åšæœ‹å…‹2077-20251016-F9-02-zzx/
    #     â”‚   â”œâ”€â”€ group_xxx_001/
    #     â”‚   â””â”€â”€ ...
    # """
    print(f"\n{'='*60}")
    print(f"â˜ï¸ å¼€å§‹ä¸Šä¼ åˆ°OSS")
    print(f"{'='*60}")
    
    # è·å–tmpæ–‡ä»¶å¤¹ä¸‹çš„å­æ–‡ä»¶å¤¹
    subfolders = [f for f in os.listdir(tmp_path) 
                  if os.path.isdir(os.path.join(tmp_path, f))]
    
    if not subfolders:
        print(f"âš ï¸ tmpæ–‡ä»¶å¤¹ä¸ºç©ºï¼Œæ— éœ€ä¸Šä¼ ")
        return True
    
    # ä»ç¬¬ä¸€ä¸ªæ–‡ä»¶å¤¹åæå–æ¸¸æˆåç§°
    first_folder = subfolders[0]
    game_name = get_game_name_from_folder(first_folder)
    
    # æ„å»ºOSSç›®æ ‡è·¯å¾„
    oss_target_path = f"{oss_base_path}{game_name}/"
    
    print(f"ğŸ“ æœ¬åœ°è·¯å¾„: {tmp_path}")
    print(f"â˜ï¸ OSSè·¯å¾„: {oss_target_path}")
    print(f"ğŸ® æ¸¸æˆåç§°: {game_name}")
    print(f"ğŸ“¦ åŒ…å«æ–‡ä»¶å¤¹: {', '.join(subfolders)}")
    
    # ç»Ÿè®¡æ–‡ä»¶æ•°é‡å’Œå¤§å°
    print(f"\nğŸ“Š ç»Ÿè®¡ä¸Šä¼ æ•°æ®...")
    total_files = 0
    total_size = 0
    for folder in subfolders:
        folder_path = os.path.join(tmp_path, folder)
        for root, dirs, files in os.walk(folder_path):
            total_files += len(files)
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    total_size += os.path.getsize(file_path)
                except:
                    pass
    
    print(f"   æ–‡ä»¶æ•°é‡: {total_files}")
    print(f"   æ€»å¤§å°: {total_size / (1024**3):.2f} GB")
    
    try:
        # æ„å»ºossutilå‘½ä»¤
        cmd = [
            OSSUTIL_PATH,
            'cp',
            '-r',           # é€’å½’ä¸Šä¼ 
            '-u',           # åªä¸Šä¼ æ–°æ–‡ä»¶æˆ–ä¿®æ”¹è¿‡çš„æ–‡ä»¶
            '--jobs', '3',  # å¹¶å‘ä»»åŠ¡æ•°ï¼ˆå¯ä»¥åŠ å¿«ä¸Šä¼ é€Ÿåº¦ï¼‰
            tmp_path,
            oss_target_path
        ]
        
        print(f"\nğŸš€ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print(f"{'='*60}")
        
        # å®æ—¶æ˜¾ç¤ºè¾“å‡ºï¼ˆossutilè‡ªå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',
            errors='ignore',
            bufsize=1,
            universal_newlines=True
        )
        
        # é€è¡Œè¾“å‡ºï¼Œä¿ç•™ossutilçš„è¿›åº¦æ˜¾ç¤º
        for line in process.stdout:
            print(line, end='')
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        return_code = process.wait()
        
        print(f"{'='*60}")
        
        if return_code == 0:
            print(f"âœ… ä¸Šä¼ æˆåŠŸï¼")
            return True
        else:
            print(f"âŒ ä¸Šä¼ å¤±è´¥ï¼è¿”å›ç : {return_code}")
            return False
            
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°ossutilå‘½ä»¤ï¼Œè¯·æ£€æŸ¥OSSUTIL_PATHé…ç½®")
        print(f"å½“å‰é…ç½®: {OSSUTIL_PATH}")
        print(f"\nğŸ’¡ æç¤ºï¼š")
        print(f"   1. ä¸‹è½½ossutil: https://help.aliyun.com/document_detail/120075.html")
        print(f"   2. é…ç½®ossutil: ossutil config")
        print(f"   3. ä¿®æ”¹è„šæœ¬ä¸­çš„OSSUTIL_PATHå˜é‡ä¸ºossutil.exeçš„å®Œæ•´è·¯å¾„")
        return False
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

# ==================== æ¸…ç†æ¨¡å— ====================
def cleanup_tmp_folder(tmp_path):
    """æ¸…ç©ºtmpæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰å†…å®¹"""
    print(f"\n{'='*60}")
    print(f"ğŸ—‘ï¸ å¼€å§‹æ¸…ç†tmpæ–‡ä»¶å¤¹")
    print(f"{'='*60}")
    
    try:
        for item in os.listdir(tmp_path):
            item_path = os.path.join(tmp_path, item)
            
            if os.path.isdir(item_path):
                print(f"   åˆ é™¤æ–‡ä»¶å¤¹: {item}")
                shutil.rmtree(item_path)
            else:
                print(f"   åˆ é™¤æ–‡ä»¶: {item}")
                os.remove(item_path)
        
        # éªŒè¯æ˜¯å¦æ¸…ç©º
        remaining = os.listdir(tmp_path)
        if not remaining:
            print(f"âœ… tmpæ–‡ä»¶å¤¹å·²æ¸…ç©º")
            return True
        else:
            print(f"âš ï¸ ä»æœ‰{len(remaining)}ä¸ªé¡¹ç›®æœªåˆ é™¤")
            return False
            
    except Exception as e:
        print(f"âŒ æ¸…ç†å‡ºé”™: {str(e)}")
        return False

# ==================== ä¸»æµç¨‹ï¼ˆä¸²è¡Œå¤„ç†ï¼‰====================
def process_single_url(url, tmp_dir, oss_base_path):
    """
    å¤„ç†å•ä¸ªURLçš„å®Œæ•´æµç¨‹ï¼š
    1. ä¸‹è½½
    2. è§£å‹åˆ°tmp/æ–‡ä»¶å¤¹å/
    3. å¤„ç†actions
    4. ä¸Šä¼ æ•´ä¸ªtmpæ–‡ä»¶å¤¹
    5. æ¸…ç©ºtmp
    """
    print(f"\n{'#'*60}")
    print(f"# å¼€å§‹å¤„ç†æ–°çš„æ•°æ®åŒ…")
    print(f"{'#'*60}")
    
    # æ­¥éª¤1: ä¸‹è½½
    filename = extract_filename_from_url(url)
    zip_path = os.path.join(tmp_dir, filename)
    
    if not download_file(url, zip_path):
        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡æ­¤URL")
        return False
    
    # æ­¥éª¤2: è§£å‹
    extracted_folder = extract_zip(zip_path, tmp_dir)
    if not extracted_folder:
        print(f"âŒ è§£å‹å¤±è´¥ï¼Œè·³è¿‡æ­¤URL")
        return False
    
    # æ­¥éª¤3: å¤„ç†
    if not process_extracted_folder(extracted_folder):
        print(f"âŒ å¤„ç†å¤±è´¥ï¼Œè·³è¿‡ä¸Šä¼ ")
        return False
    
    # æ­¥éª¤4: ä¸Šä¼ æ•´ä¸ªtmpæ–‡ä»¶å¤¹ï¼ˆä¿®æ”¹è¿™é‡Œï¼‰
    if not upload_tmp_to_oss(tmp_dir, oss_base_path):
        print(f"âŒ ä¸Šä¼ å¤±è´¥ï¼Œä¿ç•™æœ¬åœ°æ–‡ä»¶")
        return False
    
    # æ­¥éª¤5: æ¸…ç©ºtmp
    if not cleanup_tmp_folder(tmp_dir):
        print(f"âš ï¸ æ¸…ç†å¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª")
    
    print(f"\n{'#'*60}")
    print(f"# å½“å‰æ•°æ®åŒ…å¤„ç†å®Œæˆ")
    print(f"{'#'*60}\n")
    
    return True

def main():
    parser = argparse.ArgumentParser(
        description="è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµç¨‹ï¼ˆä¸²è¡Œç‰ˆæœ¬ï¼‰ï¼šé€ä¸ªä¸‹è½½â†’å¤„ç†â†’ä¸Šä¼ â†’æ¸…ç†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š
  python script.py urls.txt
  
é…ç½®è¯´æ˜ï¼š
  1. ä¿®æ”¹è„šæœ¬å¼€å¤´çš„é…ç½®å‚æ•°ï¼ˆBASE_DIRã€OSS_BASE_PATHç­‰ï¼‰
  2. ç¡®ä¿å·²å®‰è£…ossutilå¹¶é…ç½®å¥½OSSè®¿é—®æƒé™
  3. åœ¨urls.txtä¸­æ¯è¡Œæ”¾ä¸€ä¸ªä¸‹è½½é“¾æ¥
  
æµç¨‹è¯´æ˜ï¼š
  æ¯ä¸ªURLç‹¬ç«‹å¤„ç†ï¼š
    ä¸‹è½½ â†’ è§£å‹åˆ°tmp/æ–‡ä»¶å¤¹/ â†’ å¤„ç†actions â†’ ä¸Šä¼ tmp â†’ æ¸…ç©ºtmp â†’ ä¸‹ä¸€ä¸ª
        """
    )
    parser.add_argument(
        "url_file",
        help="åŒ…å«ä¸‹è½½é“¾æ¥çš„æ–‡æœ¬æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--start-from",
        type=int,
        default=1,
        help="ä»ç¬¬å‡ ä¸ªURLå¼€å§‹å¤„ç†ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼Œé»˜è®¤ä»ç¬¬1ä¸ªå¼€å§‹ï¼‰"
    )
    parser.add_argument(
        "--skip-upload",
        action="store_true",
        help="è·³è¿‡ä¸Šä¼ æ­¥éª¤ï¼ˆä»…å¤„ç†ä¸ä¸Šä¼ ï¼Œç”¨äºæµ‹è¯•ï¼‰"
    )
    parser.add_argument(
        "--keep-files",
        action="store_true",
        help="å¤„ç†å®Œæˆåä¿ç•™æœ¬åœ°æ–‡ä»¶ï¼ˆä¸æ¸…ç©ºtmpï¼‰"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥URLæ–‡ä»¶
    if not os.path.exists(args.url_file):
        print(f"âŒ URLæ–‡ä»¶ä¸å­˜åœ¨: {args.url_file}")
        return
    
    # è¯»å–URLåˆ—è¡¨
    try:
        with open(args.url_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except Exception as e:
        print(f"âŒ è¯»å–URLæ–‡ä»¶å¤±è´¥: {str(e)}")
        return
    
    if not urls:
        print(f"âŒ URLæ–‡ä»¶ä¸ºç©º")
        return
    
    # åˆ›å»ºtmpç›®å½•
    os.makedirs(BASE_DIR, exist_ok=True)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"\n{'#'*60}")
    print(f"# è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†æµç¨‹ï¼ˆä¸²è¡Œç‰ˆæœ¬ï¼‰")
    print(f"{'#'*60}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {BASE_DIR}")
    print(f"â˜ï¸ OSSåŸºç¡€è·¯å¾„: {OSS_BASE_PATH}")
    print(f"ğŸ“‹ æ€»URLæ•°é‡: {len(urls)}")
    print(f"ğŸš€ å¼€å§‹ä½ç½®: ç¬¬{args.start_from}ä¸ª")
    if args.skip_upload:
        print(f"âš ï¸ è·³è¿‡ä¸Šä¼ æ­¥éª¤ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
    if args.keep_files:
        print(f"âš ï¸ ä¿ç•™æœ¬åœ°æ–‡ä»¶ï¼ˆä¸æ¸…ç©ºtmpï¼‰")
    print(f"{'#'*60}\n")
    
    # å…¨å±€ç¡®è®¤
    print(f"âš ï¸ å¤„ç†æµç¨‹ï¼š")
    print(f"   æ¯ä¸ªURLç‹¬ç«‹å¤„ç†ï¼ˆä¸‹è½½â†’è§£å‹â†’å¤„ç†â†’ä¸Šä¼ â†’æ¸…ç©ºtmpï¼‰")
    print(f"   å¤„ç†å®Œä¸€ä¸ªæ‰ä¼šå¼€å§‹ä¸‹ä¸€ä¸ª")
    confirm = input(f"\næ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
    if confirm.lower() != 'y':
        print(f"âœ… å·²å–æ¶ˆæ“ä½œ")
        return
    
    # ç»Ÿè®¡å˜é‡
    total_urls = len(urls)
    success_count = 0
    failed_urls = []
    
    # ä¸²è¡Œå¤„ç†æ¯ä¸ªURL
    try:
        for idx, url in enumerate(urls, 1):
            # æ”¯æŒä»æŒ‡å®šä½ç½®å¼€å§‹
            if idx < args.start_from:
                print(f"â­ï¸ è·³è¿‡ç¬¬{idx}ä¸ªURL")
                continue
            
            print(f"\n{'='*60}")
            print(f"[æ€»è¿›åº¦: {idx}/{total_urls}] å¤„ç†ç¬¬{idx}ä¸ªURL")
            print(f"{'='*60}")
            
            # å¤„ç†å•ä¸ªURLçš„å®Œæ•´æµç¨‹
            try:
                if args.skip_upload:
                    # æµ‹è¯•æ¨¡å¼ï¼šåªä¸‹è½½å’Œå¤„ç†
                    filename = extract_filename_from_url(url)
                    zip_path = os.path.join(BASE_DIR, filename)
                    
                    if download_file(url, zip_path):
                        extracted_folder = extract_zip(zip_path, BASE_DIR)
                        if extracted_folder and process_extracted_folder(extracted_folder):
                            success_count += 1
                            print(f"âœ… ç¬¬{idx}ä¸ªURLå¤„ç†æˆåŠŸï¼ˆæœªä¸Šä¼ ï¼‰")
                        else:
                            failed_urls.append((idx, url))
                    else:
                        failed_urls.append((idx, url))
                        
                elif args.keep_files:
                    # ä¿ç•™æ–‡ä»¶æ¨¡å¼ï¼šä¸æ¸…ç©ºtmp
                    filename = extract_filename_from_url(url)
                    zip_path = os.path.join(BASE_DIR, filename)
                    
                    if download_file(url, zip_path):
                        extracted_folder = extract_zip(zip_path, BASE_DIR)
                        if extracted_folder and process_extracted_folder(extracted_folder):
                            if upload_tmp_to_oss(BASE_DIR, OSS_BASE_PATH):
                                success_count += 1
                                print(f"âœ… ç¬¬{idx}ä¸ªURLå¤„ç†æˆåŠŸï¼ˆå·²ä¿ç•™æ–‡ä»¶ï¼‰")
                            else:
                                failed_urls.append((idx, url))
                        else:
                            failed_urls.append((idx, url))
                    else:
                        failed_urls.append((idx, url))
                        
                else:
                    # æ­£å¸¸æ¨¡å¼ï¼šå®Œæ•´æµç¨‹
                    if process_single_url(url, BASE_DIR, OSS_BASE_PATH):
                        success_count += 1
                        print(f"âœ… ç¬¬{idx}ä¸ªURLå¤„ç†æˆåŠŸ")
                    else:
                        failed_urls.append((idx, url))
                        print(f"âŒ ç¬¬{idx}ä¸ªURLå¤„ç†å¤±è´¥")
                
            except Exception as e:
                print(f"âŒ å¤„ç†ç¬¬{idx}ä¸ªURLæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                failed_urls.append((idx, url))
                import traceback
                traceback.print_exc()
            
            # æ˜¾ç¤ºå½“å‰è¿›åº¦
            print(f"\nğŸ“Š å½“å‰è¿›åº¦: æˆåŠŸ{success_count}ä¸ªï¼Œå¤±è´¥{len(failed_urls)}ä¸ªï¼Œå‰©ä½™{total_urls - idx}ä¸ª")
    
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print(f"å·²å¤„ç†: {idx - 1}/{total_urls}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'#'*60}")
    print(f"# å¤„ç†å®Œæˆï¼")
    print(f"{'#'*60}")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡ï¼š")
    print(f"   âœ… æˆåŠŸ: {success_count}/{total_urls}")
    print(f"   âŒ å¤±è´¥: {len(failed_urls)}/{total_urls}")
    
    if failed_urls:
        print(f"\nâŒ å¤±è´¥çš„URLåˆ—è¡¨ï¼š")
        for idx, url in failed_urls:
            filename = extract_filename_from_url(url)
            print(f"   [{idx}] {filename}")
        
        # ä¿å­˜å¤±è´¥åˆ—è¡¨
        failed_file = "failed_urls.txt"
        try:
            with open(failed_file, 'w', encoding='utf-8') as f:
                for idx, url in failed_urls:
                    f.write(f"{url}\n")
            print(f"\nğŸ’¾ å¤±è´¥URLå·²ä¿å­˜åˆ°: {failed_file}")
            print(f"   å¯ä½¿ç”¨ --start-from å‚æ•°é‡æ–°å¤„ç†")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¤±è´¥URLåˆ—è¡¨å‡ºé”™: {str(e)}")
    
    print(f"{'#'*60}\n")

if __name__ == '__main__':
    main()

